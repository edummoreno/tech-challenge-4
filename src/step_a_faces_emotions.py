from collections import Counter, deque
from tqdm import tqdm

from utils_step_a import (
    garantir_diretorio,
    abrir_video,
    ler_metadados_video,
    criar_video_writer,
    detectar_faces,
    extrair_bbox_e_confianca,
    calcular_area_e_ar,
    AutoajusteLimiar,
    passa_filtros_geometricos,
    passa_filtro_confianca,
    passa_persistencia,
    recortar_rosto,
    analisar_emocao,
    desenhar_anotacoes,
    escrever_resumo
)

# ============================================================
# CONFIG (did√°tico)
# ============================================================
# A ideia aqui √© deixar tudo ‚Äúvis√≠vel‚Äù e f√°cil de mexer, sem globals espalhados.
def criar_config() -> dict:
    return {
        # caminhos
        "VIDEO_ENTRADA": "data/input.mp4",
        "VIDEO_SAIDA": "outputs/stepA_annotated.mp4",
        "RESUMO_SAIDA": "outputs/stepA_summary.txt",

        # amostragem temporal (performance)
        "FRAME_STEP": 3,

        # deepface / detec√ß√£o
        "DETECTOR_BACKEND": "opencv",
        "ENFORCE_DETECTION": False,

        # debug
        "DEBUG": True,
        "DEBUG_MAX_FRAMES": 10,

        # patch 1 (warm-up)
        "FRAMES_WARMUP_ANALISADOS": 150,

        # patch 3 (persist√™ncia)
        "K_PERSISTENCIA": 2,
        "TAMANHO_GRID": 60,

        # emo√ß√£o (crop)
        "PAD_RATIO": 0.15,   # 15% de margem no recorte do rosto
    }


# ============================================================
# FUN√á√ÉO PRINCIPAL
# ============================================================
def run_faces_emotions():
    cfg = criar_config()

    # garante pasta outputs
    garantir_diretorio("outputs")

    # abre v√≠deo e l√™ metadados
    cap = abrir_video(cfg["VIDEO_ENTRADA"])
    info = ler_metadados_video(cap)

    fps = info["fps"]
    largura = info["largura"]
    altura = info["altura"]
    total_frames = info["total_frames"]
    area_frame = info["area_frame"]

    # cria writer do v√≠deo anotado
    escritor = criar_video_writer(cfg["VIDEO_SAIDA"], fps, largura, altura)

    # ============================================================
    # LIMIARES (fallback inicial ‚Äúfrouxo‚Äù)
    # ============================================================
    # Por qu√™?
    # - Evita ‚Äúnascer travado‚Äù antes do warm-up aprender os limiares do v√≠deo.
    limiares = {
        "MIN_AREA_FACE": 40 * 40,
        "MAX_AREA_FACE": int(0.60 * area_frame),
        "MIN_AR": 0.30,
        "MAX_AR": 3.00,
        "MIN_CONFIANCA": 0.00
    }

    # Patch 1: autoajuste
    auto = AutoajusteLimiar(
        frames_warmup_analisados=cfg["FRAMES_WARMUP_ANALISADOS"],
        area_frame=area_frame,
        debug=cfg["DEBUG"]
    )

    # Patch 3: persist√™ncia
    historico_ids = deque(maxlen=10)

    # contadores para summary
    contador_emocoes = Counter()
    frames_analisados = 0
    total_faces = 0

    # ‚Äúmem√≥ria‚Äù das faces do √∫ltimo frame analisado
    # (para desenhar mesmo nos frames pulados)
    faces_ultimo_frame = []

    barra = tqdm(total=total_frames if total_frames > 0 else None, desc="Passo A ‚Äî Faces + Emo√ß√µes")
    debug_prints = 0
    indice_frame = 0

    # ============================================================
    # LOOP PRINCIPAL
    # ============================================================
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        analisou_este_frame = False

        # ------------------------------------------------------------
        # AMOSTRAGEM TEMPORAL
        # ------------------------------------------------------------
        # S√≥ fazemos detec√ß√£o+emo√ß√£o a cada N frames (performance).
        if indice_frame % cfg["FRAME_STEP"] == 0:
            try:
                faces_detectadas = detectar_faces(
                    frame_bgr=frame,
                    detector_backend=cfg["DETECTOR_BACKEND"],
                    enforce_detection=cfg["ENFORCE_DETECTION"]
                )

                if cfg["DEBUG"] and debug_prints < cfg["DEBUG_MAX_FRAMES"]:
                    print(f"[DEBUG] frame_idx={indice_frame} | faces_detectadas={len(faces_detectadas)}")
                    debug_prints += 1

                faces_validas = []

                # ------------------------------------------------------------
                # PROCESSA CADA FACE
                # ------------------------------------------------------------
                for face_dict in faces_detectadas:
                    dados = extrair_bbox_e_confianca(face_dict)
                    x, y, w, h = dados["x"], dados["y"], dados["w"], dados["h"]

                    # bbox inv√°lida
                    if w <= 0 or h <= 0:
                        continue

                    area, ar = calcular_area_e_ar(w, h)

                    # ====================================================
                    # PATCH 1 ‚Äî AUTOAJUSTE (warm-up)
                    # ====================================================
                    if not auto.limiares_definidos:
                        auto.adicionar_amostra(area, ar, dados["tem_confianca"], dados["confianca"])
                        if auto.pronto_para_definir():
                            limiares = auto.definir_limiares(limiares)

                    # ====================================================
                    # PATCH 1 ‚Äî FILTROS GEOM√âTRICOS
                    # ====================================================
                    if not passa_filtros_geometricos(area, ar, limiares):
                        continue

                    # ====================================================
                    # PATCH 2 ‚Äî FILTRO POR CONFIAN√áA (se existir)
                    # ====================================================
                    if not passa_filtro_confianca(dados["tem_confianca"], dados["confianca"], limiares):
                        continue

                    # ====================================================
                    # PATCH 3 ‚Äî PERSIST√äNCIA TEMPORAL
                    # ====================================================
                    if not passa_persistencia(historico_ids, x, y, cfg["TAMANHO_GRID"], cfg["K_PERSISTENCIA"]):
                        continue

                    # ====================================================
                    # EMO√á√ÉO (crop do frame original + analyze)
                    # ====================================================
                    face_crop = recortar_rosto(
                        frame_bgr=frame,
                        x=x, y=y, w=w, h=h,
                        largura=largura, altura=altura,
                        pad_ratio=cfg["PAD_RATIO"]
                    )

                    resultado = analisar_emocao(face_crop)
                    if resultado is None:
                        continue

                    emocao = resultado.get("dominant_emotion", "unknown")
                    dist = resultado.get("emotion", {}) or {}
                    score = float(dist.get(emocao, 0.0)) if isinstance(dist, dict) else 0.0

                    faces_validas.append({
                        "x": x, "y": y, "w": w, "h": h,
                        "emocao": emocao,
                        "score": score
                    })

                faces_ultimo_frame = faces_validas
                frames_analisados += 1
                analisou_este_frame = True

            except Exception as e:
                # Anti ‚Äúcaixa fantasma‚Äù: se falhar, n√£o reutiliza detec√ß√£o antiga
                faces_ultimo_frame = []
                if cfg["DEBUG"]:
                    print(f"[DEBUG] Exception no frame {indice_frame}: {repr(e)}")

        # ------------------------------------------------------------
        # DESENHO NO V√çDEO (sempre)
        # ------------------------------------------------------------
        desenhar_anotacoes(frame, faces_ultimo_frame, largura, altura)

        # ------------------------------------------------------------
        # AGREGA√á√ÉO TEMPORAL (somente quando analisou)
        # ------------------------------------------------------------
        if analisou_este_frame:
            total_faces += len(faces_ultimo_frame)
            for f in faces_ultimo_frame:
                contador_emocoes[f["emocao"]] += 1

        escritor.write(frame)
        indice_frame += 1
        barra.update(1)

    # ============================================================
    # FINALIZA√á√ÉO
    # ============================================================
    barra.close()
    cap.release()
    escritor.release()

    escrever_resumo(cfg["RESUMO_SAIDA"], {
        "video": cfg["VIDEO_ENTRADA"],
        "frames_totais": total_frames,
        "frames_analisados": frames_analisados,
        "frame_step": cfg["FRAME_STEP"],
        "total_faces": total_faces,
        "limiares": limiares,
        "k_persistencia": cfg["K_PERSISTENCIA"],
        "tamanho_grid": cfg["TAMANHO_GRID"],
        "contador_emocoes": contador_emocoes,
    })

    print("‚úÖ Passo A finalizado com sucesso.")
    print(f"üé• V√≠deo: {cfg['VIDEO_SAIDA']}")
    print(f"üìù Resumo: {cfg['RESUMO_SAIDA']}")


if __name__ == "__main__":
    run_faces_emotions()
